{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dfcdbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f328c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "163e62cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hub.load('https://tfhub.dev/google/movenet/multipose/lightning/1')\n",
    "movenet = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72909d0e",
   "metadata": {},
   "source": [
    "## Code For using camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89a628c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    img = frame.copy()  \n",
    "    img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 192, 256)\n",
    "    input_img = tf.cast(img,dtype=tf.int32)  \n",
    "    \n",
    "    # detection section\n",
    "    results = movenet(input_img)\n",
    "    keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n",
    "    \n",
    "    # render keypoints\n",
    "    loop_through_people(frame, keypoints_with_scores, EDGES, 0.3)\n",
    "\n",
    "    cv2.imshow('Movenet MultiPose', frame)\n",
    "  \n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "for i in range (1,5):\n",
    "    cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6fde23",
   "metadata": {},
   "source": [
    "## Code For using video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36e0ecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('football.mp4')\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    img = frame.copy()  \n",
    "    img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 352, 640)\n",
    "    input_img = tf.cast(img,dtype=tf.int32)  \n",
    "    \n",
    "    # detection section\n",
    "    results = movenet(input_img)\n",
    "    keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n",
    "    \n",
    "    # render keypoints\n",
    "    loop_through_people(frame, keypoints_with_scores, EDGES, 0.1)\n",
    "\n",
    "    cv2.imshow('Movenet MultiPose', frame)\n",
    "  \n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "for i in range (1,5):\n",
    "    cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9f6e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6611506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "for i in range (1,5):\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6746bb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[5.36000609e-01, 4.95611817e-01, 6.22851014e-01],\n",
       "        [4.84656870e-01, 5.32136738e-01, 6.09178662e-01],\n",
       "        [4.84423101e-01, 4.44147408e-01, 7.10799575e-01],\n",
       "        [4.97068226e-01, 5.80150783e-01, 5.35377800e-01],\n",
       "        [5.12050092e-01, 3.80608290e-01, 5.10407388e-01],\n",
       "        [7.07870722e-01, 7.13515759e-01, 8.00658882e-01],\n",
       "        [7.18279779e-01, 3.25003922e-01, 7.86948919e-01],\n",
       "        [7.76656508e-01, 8.04676354e-01, 2.51804180e-02],\n",
       "        [7.70112813e-01, 3.17724675e-01, 5.46771474e-03],\n",
       "        [7.53964365e-01, 7.19340563e-01, 2.32801065e-02],\n",
       "        [7.13198423e-01, 4.70181197e-01, 4.64928262e-02],\n",
       "        [7.95916080e-01, 6.90194130e-01, 4.00912832e-05],\n",
       "        [7.86388159e-01, 4.63531166e-01, 1.66747759e-05],\n",
       "        [7.51423359e-01, 6.78015590e-01, 1.40746927e-03],\n",
       "        [7.46354103e-01, 3.82296264e-01, 3.97907058e-03],\n",
       "        [3.86938572e-01, 6.01911485e-01, 1.70240796e-03],\n",
       "        [4.47508961e-01, 5.89648306e-01, 9.53949464e-04]],\n",
       "\n",
       "       [[3.86754125e-01, 3.85726616e-02, 2.43415171e-03],\n",
       "        [3.18451315e-01, 1.53574362e-01, 1.24788820e-03],\n",
       "        [3.73880833e-01, 3.78812514e-02, 8.82423192e-04],\n",
       "        [3.20502371e-01, 1.50429666e-01, 1.26777543e-03],\n",
       "        [3.72592777e-01, 4.46344391e-02, 1.58923713e-03],\n",
       "        [4.22035992e-01, 1.30265817e-01, 3.57667054e-03],\n",
       "        [3.78839344e-01, 4.60678041e-02, 3.49100330e-03],\n",
       "        [4.45935220e-01, 1.47791475e-01, 4.29828838e-03],\n",
       "        [3.53079736e-01, 1.87822655e-02, 1.28573785e-03],\n",
       "        [4.17357385e-01, 1.51307166e-01, 2.82859989e-03],\n",
       "        [3.63484591e-01, 1.12134218e-02, 3.28609836e-03],\n",
       "        [5.55552244e-01, 1.10553421e-01, 3.63916811e-03],\n",
       "        [5.19836426e-01, 7.94325247e-02, 2.37231632e-03],\n",
       "        [6.68812215e-01, 1.20040342e-01, 1.67005311e-03],\n",
       "        [6.34581983e-01, 1.84234157e-02, 1.92144269e-03],\n",
       "        [7.60395408e-01, 1.04739524e-01, 2.40564928e-03],\n",
       "        [7.44151175e-01, 6.51972219e-02, 2.28879205e-03]],\n",
       "\n",
       "       [[9.33142424e-01, 9.85547423e-01, 6.06497703e-03],\n",
       "        [7.56686091e-01, 9.27387953e-01, 2.28284346e-03],\n",
       "        [7.55942881e-01, 9.28242028e-01, 2.26423796e-03],\n",
       "        [7.52346694e-01, 9.18933153e-01, 2.01318762e-03],\n",
       "        [7.49294758e-01, 9.23453629e-01, 1.54580665e-03],\n",
       "        [7.60996699e-01, 9.22647059e-01, 4.25241189e-03],\n",
       "        [7.53981948e-01, 9.21019852e-01, 1.34362816e-03],\n",
       "        [1.03295755e+00, 9.86526906e-01, 3.71796777e-03],\n",
       "        [9.14156437e-01, 8.72403979e-01, 1.50358886e-03],\n",
       "        [9.44112778e-01, 9.69745815e-01, 1.52759056e-03],\n",
       "        [9.71154690e-01, 9.61060762e-01, 1.87413313e-03],\n",
       "        [9.73455548e-01, 9.54832137e-01, 9.10595874e-04],\n",
       "        [9.65704978e-01, 9.12396073e-01, 4.33310313e-04],\n",
       "        [1.01116216e+00, 1.01329648e+00, 6.16671332e-06],\n",
       "        [9.98043239e-01, 9.98094857e-01, 2.64273076e-05],\n",
       "        [1.01247871e+00, 9.53062177e-01, 3.40895596e-08],\n",
       "        [9.72333491e-01, 1.00199354e+00, 8.73731096e-06]],\n",
       "\n",
       "       [[6.33174121e-01, 6.94901884e-01, 5.65404072e-03],\n",
       "        [6.20406985e-01, 6.94856465e-01, 1.43839838e-03],\n",
       "        [6.48539305e-01, 7.45136738e-01, 7.35495996e-04],\n",
       "        [6.26681149e-01, 6.85974896e-01, 1.46529370e-03],\n",
       "        [6.26909137e-01, 6.74827814e-01, 1.43108511e-04],\n",
       "        [7.15142310e-01, 7.26397395e-01, 5.30718744e-01],\n",
       "        [7.03970313e-01, 7.00090706e-01, 3.23535758e-03],\n",
       "        [7.58425653e-01, 7.87782907e-01, 6.33747727e-02],\n",
       "        [7.43170142e-01, 7.49547184e-01, 3.62546509e-03],\n",
       "        [7.48318076e-01, 8.00540388e-01, 2.58054789e-02],\n",
       "        [7.36638904e-01, 7.81731665e-01, 1.00917555e-02],\n",
       "        [7.77469099e-01, 7.13779330e-01, 6.12184012e-05],\n",
       "        [7.66827464e-01, 7.15285122e-01, 1.81970299e-05],\n",
       "        [7.31530190e-01, 8.06257129e-01, 2.06834767e-02],\n",
       "        [7.18101561e-01, 7.96402276e-01, 2.36957017e-02],\n",
       "        [7.48579860e-01, 8.10669541e-01, 1.59159920e-03],\n",
       "        [7.47278929e-01, 7.99566984e-01, 2.35958467e-03]],\n",
       "\n",
       "       [[5.36000609e-01, 4.95611817e-01, 6.22851014e-01],\n",
       "        [4.92227614e-01, 5.30377150e-01, 7.00550154e-03],\n",
       "        [4.95578587e-01, 4.50129598e-01, 1.74100548e-02],\n",
       "        [5.07368326e-01, 5.80732346e-01, 1.23944469e-01],\n",
       "        [5.13749063e-01, 3.82576674e-01, 3.00957412e-01],\n",
       "        [7.07084954e-01, 6.77109599e-01, 1.92904919e-02],\n",
       "        [7.18279779e-01, 3.25003922e-01, 7.86948919e-01],\n",
       "        [7.64517188e-01, 6.51485324e-01, 1.04711100e-03],\n",
       "        [7.71617532e-01, 3.10512662e-01, 4.78866603e-03],\n",
       "        [7.55733907e-01, 6.22201145e-01, 1.72472522e-02],\n",
       "        [7.63991356e-01, 3.57021034e-01, 7.58381793e-03],\n",
       "        [7.98919499e-01, 6.27390504e-01, 9.02394822e-06],\n",
       "        [7.87319183e-01, 4.50337559e-01, 1.42700646e-05],\n",
       "        [7.58480668e-01, 6.41703069e-01, 2.24722596e-03],\n",
       "        [7.37745881e-01, 3.27566922e-01, 5.09809284e-03],\n",
       "        [7.03547955e-01, 4.94786799e-01, 6.75805984e-03],\n",
       "        [6.96842253e-01, 4.98968273e-01, 2.00474896e-02]],\n",
       "\n",
       "       [[9.33142424e-01, 9.85547423e-01, 6.06497703e-03],\n",
       "        [9.19812977e-01, 9.77815568e-01, 1.07218872e-03],\n",
       "        [9.30288374e-01, 9.64990139e-01, 1.78758055e-03],\n",
       "        [9.17543530e-01, 9.60834742e-01, 2.05087545e-03],\n",
       "        [9.23333108e-01, 9.34384167e-01, 1.62634836e-03],\n",
       "        [9.48675871e-01, 9.36036110e-01, 4.68850974e-03],\n",
       "        [9.32785392e-01, 9.12750721e-01, 9.90285655e-04],\n",
       "        [1.03295755e+00, 9.86526906e-01, 3.71796777e-03],\n",
       "        [9.08934534e-01, 9.26192880e-01, 4.95173212e-04],\n",
       "        [9.61042941e-01, 9.76889133e-01, 8.99366569e-04],\n",
       "        [8.07180345e-01, 9.42895234e-01, 3.73009290e-03],\n",
       "        [9.73455548e-01, 9.54832137e-01, 9.10595874e-04],\n",
       "        [9.65842783e-01, 9.61098194e-01, 1.84171324e-04],\n",
       "        [1.01116216e+00, 1.01329648e+00, 6.16671332e-06],\n",
       "        [9.98043239e-01, 9.98094857e-01, 2.64273076e-05],\n",
       "        [1.01247871e+00, 9.53062177e-01, 3.40895596e-08],\n",
       "        [9.72333491e-01, 1.00199354e+00, 8.73731096e-06]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['output_0'].numpy()[:,:,:51].reshape((6,17,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc0d182",
   "metadata": {},
   "source": [
    "## [nose, left eye, right eye, left ear, right ear, left shoulder, right shoulder, left elbow, right elbow, left wrist, right wrist, left hip, right hip, left knee, right knee, left ankle, right ankle]. The remaining 5 elements [ymin, xmin, ymax, xmax, score] represent the region of the bounding box (in normalized coordinates) and the confidence score of the instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98126c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 17, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_with_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e5a1a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5293552 , 0.44841567, 0.5881928 ],\n",
       "       [0.47638726, 0.49198368, 0.7671269 ],\n",
       "       [0.4674847 , 0.39918908, 0.6593186 ],\n",
       "       [0.49483964, 0.55325747, 0.6978161 ],\n",
       "       [0.475124  , 0.3472734 , 0.38256213],\n",
       "       [0.63364697, 0.65680563, 0.26014534],\n",
       "       [0.6996311 , 0.20653917, 0.63010436],\n",
       "       [0.7434801 , 0.9338841 , 0.13660638],\n",
       "       [0.76694494, 0.14743172, 0.04152149],\n",
       "       [0.71010214, 0.8250694 , 0.05455555],\n",
       "       [0.72634023, 0.40200368, 0.03088059],\n",
       "       [0.8010471 , 0.63170505, 0.00651539],\n",
       "       [0.7877835 , 0.3853634 , 0.00736779],\n",
       "       [0.7606194 , 0.69573003, 0.00158437],\n",
       "       [0.74796444, 0.2949429 , 0.00869546],\n",
       "       [0.48618102, 0.5794364 , 0.00173463],\n",
       "       [0.57174945, 0.5704317 , 0.002585  ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_with_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbcbc6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to loop through each person detected and render\n",
    "def loop_through_people(frame, keypoints_with_scores, edges, confidence_threshold):\n",
    "    for person in keypoints_with_scores:\n",
    "        draw_connections(frame, person, edges, confidence_threshold)\n",
    "        draw_keypoints(frame, person, confidence_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ee320c",
   "metadata": {},
   "source": [
    "# Draw keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f91521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 4, (0,255,0), -1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be892c55",
   "metadata": {},
   "source": [
    "# Draw Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4553297",
   "metadata": {},
   "outputs": [],
   "source": [
    "EDGES = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e60b0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, c1 = shaped[p1]\n",
    "        y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
    "            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d4df0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa74b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d4ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, c1 = shaped[p1]\n",
    "        y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
    "            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 2)\n",
    "# function to loop through each person detected and render\n",
    "def loop_through_people(frame, keypoints_with_scores, edges, confidence_threshold):\n",
    "    for person in keypoints_with_scores:\n",
    "        draw_connections(frame, person, edges, confidence_threshold)\n",
    "        draw_keypoints(frame, person, confidence_threshold)\n",
    "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 4, (0,255,0), -1) \n",
    "EDGES = {\n",
    "(0, 1): 'm',(0, 2): 'c',(1, 3): 'm',(2, 4): 'c',(0, 5): 'm',(0, 6): 'c',(5, 7): 'm',(7, 9): 'm',(6, 8): 'c',(8, 10): 'c',(5, 6): 'y',(5, 11): 'm',(6, 12): 'c',(11, 12): 'y',(11, 13): 'm',(13, 15): 'm',(12, 14): 'c',(14, 16): 'c'\n",
    "}\n",
    "cap = cv2.VideoCapture('football.mp4')\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    img = frame.copy()  \n",
    "    img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 352, 640)\n",
    "    input_img = tf.cast(img,dtype=tf.int32)  \n",
    "    \n",
    "    # detection section\n",
    "    results = movenet(input_img)\n",
    "    keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n",
    "    \n",
    "    # render keypoints\n",
    "    loop_through_people(frame, keypoints_with_scores, EDGES, 0.1)\n",
    "\n",
    "    cv2.imshow('Movenet MultiPose', frame)\n",
    "  \n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "for i in range (1,5):\n",
    "    cv2.waitKey(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
